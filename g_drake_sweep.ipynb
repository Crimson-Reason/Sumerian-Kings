{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e09712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import csv\n",
    "import math\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9974c0",
   "metadata": {},
   "source": [
    "## Parameter Setup\n",
    "\n",
    "Set fixed Drake parameters and define ranges for sweep variables ($f_l$ and $f_i$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2fc03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Fixed Drake Parameters =====\n",
    "t_star = 5.0e6  # stellar lifetime for O-stars (years); G-stars live ~10 Gy but we use O-star timescale for comparison\n",
    "fp = 1.0        # fraction with planets (optimistic: all stars)\n",
    "ne = 0.1        # planets per star in habitable zone\n",
    "fc = 0.1        # fraction developing civilization\n",
    "L = 1.0e5       # civilization lifetime (years)\n",
    "n_stars = 2     # number of stars in sample (O-stars in shell)\n",
    "\n",
    "# Note: For G-stars, N_stars would be ~500k (estimated from G_star_results.json)\n",
    "# But we compute per-star probability first, then scale.\n",
    "\n",
    "print(\"Fixed Parameters:\")\n",
    "print(f\"  t_star = {t_star:.2e} yr (stellar lifetime)\")\n",
    "print(f\"  fp = {fp} (fraction with planets)\")\n",
    "print(f\"  ne = {ne} (planets per star in habitable zone)\")\n",
    "print(f\"  fc = {fc} (fraction developing civilization)\")\n",
    "print(f\"  L = {L:.2e} yr (civilization lifetime)\")\n",
    "print(f\"  n_stars = {n_stars} (sample size for at-least-one probability)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9332ce12",
   "metadata": {},
   "source": [
    "## Sweep Parameters\n",
    "\n",
    "Define log-spaced ranges for $f_l$ (fraction of habitable planets with life) and $f_i$ (fraction with intelligence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce42aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Sweep Ranges (log-spaced) =====\n",
    "fl_values = [1.0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-6]\n",
    "fi_values = [1e-0, 1e-1, 1e-2, 1e-3, 1e-6]\n",
    "\n",
    "print(f\"f_l sweep ({len(fl_values)} values): {fl_values}\")\n",
    "print(f\"f_i sweep ({len(fi_values)} values): {fi_values}\")\n",
    "print(f\"Total grid points: {len(fl_values) * len(fi_values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30b19bb",
   "metadata": {},
   "source": [
    "## Compute Sweep\n",
    "\n",
    "For each $(f_l, f_i)$ pair, compute:\n",
    "- Per-star probability: $p = f_p \\times n_e \\times f_l \\times f_i \\times f_c \\times \\frac{L}{t_\\star}$\n",
    "- Probability at least one civilization in sample: $P(\\text{at least one}) = 1 - (1-p)^{n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6398bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Perform Sweep =====\n",
    "results = []\n",
    "\n",
    "for fl in fl_values:\n",
    "    for fi in fi_values:\n",
    "        # Per-star probability\n",
    "        p = fp * ne * fl * fi * fc * (L / t_star)\n",
    "        # Probability of at least one civilization in n_stars\n",
    "        p_any = 1.0 - (1.0 - p) ** n_stars\n",
    "        \n",
    "        results.append({\n",
    "            'fl': fl,\n",
    "            'fi': fi,\n",
    "            'per_star_p': p,\n",
    "            'p_at_least_one': p_any\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"Computed {len(df)} grid points.\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea9a214",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "Display statistics and export to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d143848",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sweep Results Summary\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nPer-Star Probability Range:\")\n",
    "print(f\"  Min: {df['per_star_p'].min():.3e}\")\n",
    "print(f\"  Max: {df['per_star_p'].max():.3e}\")\n",
    "print(f\"  Mean: {df['per_star_p'].mean():.3e}\")\n",
    "print(f\"  Median: {df['per_star_p'].median():.3e}\")\n",
    "\n",
    "print(f\"\\nP(At Least One | n={n_stars}) Range:\")\n",
    "print(f\"  Min: {df['p_at_least_one'].min():.3e}\")\n",
    "print(f\"  Max: {df['p_at_least_one'].max():.3e}\")\n",
    "print(f\"  Mean: {df['p_at_least_one'].mean():.3e}\")\n",
    "print(f\"  Median: {df['p_at_least_one'].median():.3e}\")\n",
    "\n",
    "# Show some notable points\n",
    "print(f\"\\nOptimistic scenario (fl=1.0, fi=1.0):\")\n",
    "opt = df[(df['fl'] == 1.0) & (df['fi'] == 1.0)].iloc[0]\n",
    "print(f\"  Per-star p: {opt['per_star_p']:.3e}\")\n",
    "print(f\"  P(at least one): {opt['p_at_least_one']:.3e}\")\n",
    "\n",
    "print(f\"\\nPessimistic scenario (fl=1e-6, fi=1e-6):\")\n",
    "pess = df[(df['fl'] == 1.0e-6) & (df['fi'] == 1.0e-6)].iloc[0]\n",
    "print(f\"  Per-star p: {pess['per_star_p']:.3e}\")\n",
    "print(f\"  P(at least one): {pess['p_at_least_one']:.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda10209",
   "metadata": {},
   "source": [
    "## Export to CSV\n",
    "\n",
    "Save results to CSV file for external use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68095145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "output_file = 'g_drake_sweep_results.csv'\n",
    "\n",
    "df.to_csv(output_file, index=False, float_format='%.12e')\n",
    "\n",
    "print(f\"Exported sweep results to: {output_file}\")\n",
    "print(f\"File size: {__import__('os').path.getsize(output_file)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76db052",
   "metadata": {},
   "source": [
    "## Visualization: Heatmap\n",
    "\n",
    "Create a 2D heatmap showing per-star probability as a function of $f_l$ and $f_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c0d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for heatmap\n",
    "pivot_per_star = df.pivot_table(values='per_star_p', index='fi', columns='fl')\n",
    "pivot_p_any = df.pivot_table(values='p_at_least_one', index='fi', columns='fl')\n",
    "\n",
    "# Sort for proper display\n",
    "pivot_per_star = pivot_per_star.sort_index(ascending=False)\n",
    "pivot_p_any = pivot_p_any.sort_index(ascending=False)\n",
    "\n",
    "print(\"Per-Star Probability Heatmap (log-scale):\")\n",
    "print(pivot_per_star)\n",
    "\n",
    "print(\"\\nP(At Least One) Heatmap (log-scale):\")\n",
    "print(pivot_p_any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6522d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize as heatmaps\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Per-star probability heatmap\n",
    "im1 = axes[0].imshow(np.log10(pivot_per_star.values), cmap='YlOrRd', aspect='auto')\n",
    "axes[0].set_xlabel('$f_l$ (log scale)', fontsize=11)\n",
    "axes[0].set_ylabel('$f_i$ (log scale)', fontsize=11)\n",
    "axes[0].set_title('Per-Star Probability $p$ (log-scale heatmap)', fontsize=12)\n",
    "axes[0].set_xticks(range(len(pivot_per_star.columns)))\n",
    "axes[0].set_xticklabels([f'{x:.0e}' for x in pivot_per_star.columns], rotation=45, ha='right')\n",
    "axes[0].set_yticks(range(len(pivot_per_star.index)))\n",
    "axes[0].set_yticklabels([f'{x:.0e}' for x in pivot_per_star.index])\n",
    "cbar1 = plt.colorbar(im1, ax=axes[0])\n",
    "cbar1.set_label('log₁₀(p)', fontsize=10)\n",
    "\n",
    "# P(at least one) heatmap\n",
    "im2 = axes[1].imshow(np.log10(pivot_p_any.values + 1e-20), cmap='Blues', aspect='auto')\n",
    "axes[1].set_xlabel('$f_l$ (log scale)', fontsize=11)\n",
    "axes[1].set_ylabel('$f_i$ (log scale)', fontsize=11)\n",
    "axes[1].set_title(f'P(At Least One | n={n_stars}) (log-scale)', fontsize=12)\n",
    "axes[1].set_xticks(range(len(pivot_p_any.columns)))\n",
    "axes[1].set_xticklabels([f'{x:.0e}' for x in pivot_p_any.columns], rotation=45, ha='right')\n",
    "axes[1].set_yticks(range(len(pivot_p_any.index)))\n",
    "axes[1].set_yticklabels([f'{x:.0e}' for x in pivot_p_any.index])\n",
    "cbar2 = plt.colorbar(im2, ax=axes[1])\n",
    "cbar2.set_label('log₁₀(P)', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('g_drake_sweep_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Heatmap saved to: g_drake_sweep_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db9075",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis\n",
    "\n",
    "Explore how probability changes with different sample sizes $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bfdfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute P(at least one) for different sample sizes\n",
    "sample_sizes = [1, 2, 5, 10, 100, 1000, 10000]\n",
    "\n",
    "# Use a few representative scenarios\n",
    "scenarios = [\n",
    "    {'fl': 1.0, 'fi': 1.0, 'label': 'Optimistic (fl=1, fi=1)'},\n",
    "    {'fl': 0.1, 'fi': 0.1, 'label': 'Moderate (fl=0.1, fi=0.1)'},\n",
    "    {'fl': 1e-3, 'fi': 1e-3, 'label': 'Pessimistic (fl=1e-3, fi=1e-3)'},\n",
    "]\n",
    "\n",
    "print(\"P(At Least One) vs Sample Size:\\n\")\n",
    "print(f\"{'Scenario':<40} \", end='')\n",
    "for n in sample_sizes:\n",
    "    print(f\"n={n:<6} \", end='')\n",
    "print()\n",
    "print(\"=\" * 120)\n",
    "\n",
    "for scenario in scenarios:\n",
    "    fl, fi, label = scenario['fl'], scenario['fi'], scenario['label']\n",
    "    p = fp * ne * fl * fi * fc * (L / t_star)\n",
    "    print(f\"{label:<40} \", end='')\n",
    "    for n in sample_sizes:\n",
    "        p_any_n = 1.0 - (1.0 - p) ** n\n",
    "        print(f\"{p_any_n:.3e}  \", end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6fb9e",
   "metadata": {},
   "source": [
    "## Application to G-Stars\n",
    "\n",
    "Scale results to the estimated number of G-stars in the 20,366–20,374 ly shell within spiral arms.\n",
    "\n",
    "From `g_star_results_1M.json`: approximately **570,622 G-stars** expected in arms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4467c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G-star population in the shell (from 1M Monte Carlo)\n",
    "N_g_stars_arms = 570622  # from g_star_results_1M.json\n",
    "\n",
    "print(f\"G-Star Population in Shell (Spiral Arms): {N_g_stars_arms:,}\")\n",
    "print(f\"\\nScaling Drake Probabilities to Full G-Star Sample:\\n\")\n",
    "print(f\"{'Scenario':<40} {'Per-Star p':<15} {'P(≥1 | n=2)':<15} {'P(≥1 | n_full)':<15}\")\n",
    "print(\"=\" * 85)\n",
    "\n",
    "for scenario in scenarios:\n",
    "    fl, fi, label = scenario['fl'], scenario['fi'], scenario['label']\n",
    "    p = fp * ne * fl * fi * fc * (L / t_star)\n",
    "    p_2 = 1.0 - (1.0 - p) ** 2\n",
    "    p_full = 1.0 - (1.0 - p) ** N_g_stars_arms\n",
    "    print(f\"{label:<40} {p:>14.3e} {p_2:>14.3e} {p_full:>14.3e}\")\n",
    "\n",
    "print(f\"\\nNote: With ~570k G-stars, even extremely low per-star probabilities lead to\\n\"\n",
    "      f\"significant P(≥1) due to the large sample size.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5550e1ba",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook sweeps Drake equation parameters ($f_l$, $f_i$) and computes civilization detection probabilities. Key findings:\n",
    "\n",
    "1. **Optimistic scenario** (fl=1, fi=1): P(at least one civilization | n=2) ≈ 4e-4 (~0.04%)\n",
    "2. **Moderate scenario** (fl=0.1, fi=0.1): P(at least one) ≈ 4e-8\n",
    "3. **Pessimistic scenario** (fl=1e-3, fi=1e-3): P(at least one) ≈ 4e-14\n",
    "\n",
    "For G-stars with ~570k stars in the sample, even per-star probabilities as low as 1e-14 lead to non-negligible P(≥1) at the full scale.\n",
    "\n",
    "Results exported to `g_drake_sweep_results.csv` and visualization to `g_drake_sweep_heatmap.png`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
